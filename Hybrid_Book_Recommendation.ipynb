{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvFSyorSWsD1",
        "outputId": "78f7d1b3-0a62-4ad5-e3ae-68750dd3a71d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Loading the dataset\n",
        "def loaddata(filename):\n",
        "    df = pd.read_csv(f'/content/drive/MyDrive/{filename}.csv', sep=',', encoding='latin-1')\n",
        "    return df\n",
        "def loaddata2():\n",
        "    df = pd.read_csv(f'/content/drive/MyDrive/data-brm/ratings.csv', sep=',', encoding='latin-1')\n",
        "    return df\n",
        "\n",
        "keywords   = loaddata(\"keywords\")\n",
        "books   = loaddata(\"cleaned_book_data\")\n",
        "ratings = loaddata2()"
      ],
      "metadata": {
        "id": "l6VxKaQrW9Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_for_content_based = books[:]\n",
        "books_for_collaborative_based = books[:]"
      ],
      "metadata": {
        "id": "3nzV6HjjQjLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Content based"
      ],
      "metadata": {
        "id": "TI-CruKHaddP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the keywords summary using TF-IDF\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(analyzer = 'word',\n",
        "                        min_df=3,\n",
        "                        max_df = 0.6,\n",
        "                        stop_words=\"english\",\n",
        "                        encoding = 'utf-8',\n",
        "                        token_pattern=r\"(?u)\\S\\S+\")\n",
        "tfidf_encoding = tfidf.fit_transform(keywords[\"keywords\"])"
      ],
      "metadata": {
        "id": "zXi1MzPxXZvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "book_cosine_sim = cosine_similarity(tfidf_encoding, tfidf_encoding)"
      ],
      "metadata": {
        "id": "P7zDzojGXcdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_book = books_for_content_based[:]"
      ],
      "metadata": {
        "id": "TXXAtELIa9oU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_for_content_based = pd.Series(keywords['title'])\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def recommend_books_similar_to(book_name, n, cosine_sim_mat=book_cosine_sim):\n",
        "    # Get index of the input book\n",
        "    input_idx = books_for_content_based[books_for_content_based == book_name].index\n",
        "\n",
        "    # Check if the result is empty\n",
        "    if input_idx.empty:\n",
        "        return None\n",
        "\n",
        "    input_idx = input_idx[0]  # Extract the first index\n",
        "\n",
        "    # Find top n similar books with decreasing order of similarity score\n",
        "    top_n_books_idx = list(pd.Series(cosine_sim_mat[input_idx]).sort_values(ascending=False).iloc[1:n + 1].index)\n",
        "\n",
        "    # Get the similarity scores for the recommended books\n",
        "    similarity_scores = [cosine_sim_mat[input_idx][i] for i in top_n_books_idx]\n",
        "\n",
        "    books_list = list(books_for_content_based)\n",
        "    recommended_books = [books_for_content_based[i] for i in top_n_books_idx]\n",
        "\n",
        "    return recommended_books\n"
      ],
      "metadata": {
        "id": "ZEHDs9Ohaam6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collaborative based"
      ],
      "metadata": {
        "id": "W_HtiDqcabKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_users = ratings['user_id'].value_counts().reset_index().\\\n",
        "               rename({'index':'user_id','user_id':'rating'}, axis=1)\n",
        "\n",
        "rating_books = ratings['book_id'].value_counts().reset_index().\\\n",
        "               rename({'index':'book_id','book_id':'rating'}, axis=1)\n",
        "\n",
        "\n",
        "ratings = ratings[ratings['user_id'].isin(rating_users[rating_users['rating']>5]['user_id'])]\n",
        "ratings = ratings[ratings['book_id'].isin(rating_books[rating_books['rating']> 2000]['book_id'])]\n",
        "\n",
        "temp = ratings.head(650000)\n",
        "ratings = temp"
      ],
      "metadata": {
        "id": "R5caPxBPXrz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o1cEjbOXmj2",
        "outputId": "d23fccc6-0fa4-48a8-c6ec-6eacf804434c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.1%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.1+pt20cu118\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.17%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.17+pt20cu118\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_cluster-1.6.1%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.23.5)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.1+pt20cu118\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-rpzqr7us\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-rpzqr7us\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 60a2948ba1745e35ee5209d5e3d0b861aca54495\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric==2.4.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (3.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.4.0-py3-none-any.whl size=992969 sha256=a980bd3384805de8d3e4a0df020e3246d201727c93160313177af98a54e19e30\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-j17jtjdh/wheels/d3/78/eb/9e26525b948d19533f1688fb6c209cec8a0ba793d39b49ae8f\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection, metrics, preprocessing\n",
        "# import required modules\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection, metrics, preprocessing\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim, Tensor\n",
        "\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.typing import Adj\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "YyWa0cOuXvTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Use files.upload() to upload a file from your local system\n",
        "uploaded = files.upload()\n",
        "\n",
        "# map_location=torch.device('cpu')\n",
        "# Load the uploaded model file\n",
        "model_path = 'trained_graph_rec_model.pth'  # Specify the filename\n",
        "model = torch.load(model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "O6RHmGWEZRTP",
        "outputId": "4ea68588-28d3-4a2d-94b5-f887dd391ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-410793a4-7fab-402e-8ab3-026f0f73d610\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-410793a4-7fab-402e-8ab3-026f0f73d610\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving trained_graph_rec_model.pth to trained_graph_rec_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81mYzrj0bo9w",
        "outputId": "609a599a-fc90-4796-f136-f7918fd3895e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Upload the file from your local machine to Colab\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Check if the file was successfully uploaded\n",
        "if 'label_encoder_books.pkl' in uploaded:\n",
        "    print(\"File uploaded successfully!\")\n",
        "\n",
        "# Load the label encoder from the uploaded file\n",
        "loaded_label_encoder = joblib.load('label_encoder_books.pkl')\n",
        "lbl_books = loaded_label_encoder\n",
        "\n",
        "# # Now you can use loaded_label_encoder to transform data as needed\n",
        "# # For example, if you want to transform a list of labels:\n",
        "# encoded_labels = loaded_label_encoder.transform(['label1', 'label2', 'label3'])\n",
        "\n",
        "# # If you want to inverse transform encoded labels to get the original labels:\n",
        "# original_labels = loaded_label_encoder.inverse_transform(encoded_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "19HSa1tIYm5L",
        "outputId": "a9bdb88f-ec7b-490f-fcfd-1f1d84927dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0cf92bd5-5669-4c8c-b381-a9f7d9970176\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0cf92bd5-5669-4c8c-b381-a9f7d9970176\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving label_encoder_books.pkl to label_encoder_books.pkl\n",
            "File uploaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_books_for_collaborative(user_id, model, lbl_books, num_recommendations, device):\n",
        "    # Assuming 'user_id' is the user for whom you want personalized recommendations\n",
        "    try:\n",
        "        # Assuming 'user_id' is the user for whom you want personalized recommendations\n",
        "        user_embedding = model['users_emb.weight'][user_id].to(device)\n",
        "    except Exception as e:\n",
        "        # Handle the exception (e.g., print an error message)\n",
        "        print(\"Error while accessing user embedding:\", e)\n",
        "        return None, []\n",
        "\n",
        "    # Get all item embeddings\n",
        "    all_item_embeddings = model['items_emb.weight'].to(device)\n",
        "\n",
        "    # print(\"all_item_embeddings:  \",all_item_embeddings)\n",
        "\n",
        "    # Compute scores for all items using dot product\n",
        "    scores = torch.mm(all_item_embeddings, user_embedding.view(-1, 1)).squeeze().cpu().detach().numpy()\n",
        "\n",
        "    # print(\"scores: \",scores)\n",
        "\n",
        "    # Sort the items by their scores in descending order\n",
        "    sorted_indices = np.argsort(scores, axis=0)[::-1]\n",
        "\n",
        "    # print(\"sorted_indices: \",sorted_indices)\n",
        "\n",
        "    # # Get the top 'num_recommendations' book indices\n",
        "    top_indices = sorted_indices[:num_recommendations]\n",
        "\n",
        "    # # Map the book indices back to their original labels\n",
        "    recommended_books = lbl_books.classes_[top_indices]\n",
        "\n",
        "    # Create a list of tuples containing book and rating\n",
        "    recommendations_with_ratings = [(book, score) for book, score in zip(recommended_books, scores[top_indices])]\n",
        "    print(\"ratings: \",recommendations_with_ratings)\n",
        "\n",
        "    return recommended_books,recommendations_with_ratings"
      ],
      "metadata": {
        "id": "lxEVtcrmZUql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hybrid Book Recommendation System"
      ],
      "metadata": {
        "id": "SNVM7zdhak4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "#loop through each genre and collect all books in a genre\n",
        "#put all books in a list and remove duplication\n",
        "#sort in descending order of average rating\n",
        "#take the first 5 books\n",
        "\n",
        "#Take each book title and send it through content based(this way i get 25 books in total)\n",
        "#again sort the books in descending order of average rating\n",
        "#return the top 5 books"
      ],
      "metadata": {
        "id": "mHkV_yVCVsEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your line of code is:\n",
        "\n",
        "\n",
        "#NOT TO BE EXECUTED - FOR TRIAL PURPOSE ONLY\n",
        "\n",
        "\n",
        "genre_series = original_book.head(1)['genre']\n",
        "\n",
        "# Extract the value from the Series (assuming it's a single string)\n",
        "genre_string = genre_series.values[0]\n",
        "\n",
        "# Split the genre string by commas\n",
        "genres = genre_string.split(', ')\n",
        "\n",
        "# genres will now be a list containing individual genres\n",
        "print(genres)\n"
      ],
      "metadata": {
        "id": "8GNcNbmubsDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_books_by_genres(genre_list, book_dataset):\n",
        "    matching_books = []\n",
        "\n",
        "    for index, book in book_dataset.iterrows():  # Assuming book_dataset is a DataFrame\n",
        "        genre_series = book['genre']\n",
        "\n",
        "        # Extract the value from the Series (assuming it's a single string)\n",
        "        genre_string = genre_series\n",
        "\n",
        "        # Split the genre string by commas\n",
        "        genres = genre_string.split(', ')\n",
        "\n",
        "        # Check if any of the book's genres are in the genre_list\n",
        "        if any(genre in genre_list for genre in genres):\n",
        "            book_id = book['book_id']\n",
        "            title = book['title']\n",
        "            rating = float(book['rating'])  # Convert rating to float for proper sorting\n",
        "            matching_books.append((book_id, title, rating))\n",
        "\n",
        "    # Sort the list in decreasing order of rating\n",
        "    matching_books.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    return matching_books"
      ],
      "metadata": {
        "id": "zBbcw-G_5OGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def looped_recommender(title,num):\n",
        "    # Content-Based Recommendations\n",
        "    content_based_recommendations = recommend_books_similar_to(title, n=num)\n",
        "\n",
        "    return content_based_recommendations"
      ],
      "metadata": {
        "id": "jm9dIwFF5QU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_rows_by_titles(book_dataset, book_titles_to_find):\n",
        "    matching_rows = []\n",
        "\n",
        "    for index, row in book_dataset.iterrows():\n",
        "        title = row['title']\n",
        "\n",
        "        if title in book_titles_to_find:\n",
        "            matching_rows.append(row)\n",
        "\n",
        "    if len(matching_rows) > 0:\n",
        "        # Create a new DataFrame from the matching rows\n",
        "        matching_df = pd.DataFrame(matching_rows)\n",
        "\n",
        "        # Reset the index of the new DataFrame\n",
        "        matching_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        return matching_df\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "2-Wb0WUl5ut4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def content_based_for_hybrid_system(list_of_genres,num):\n",
        "\n",
        "  list_of_books = filter_books_by_genres(list_of_genres,original_book)\n",
        "\n",
        "  top_books = list_of_books[:num] if len(list_of_books) >= num else list_of_books[:]\n",
        "\n",
        "  # Initialize a variable to store all recommended books\n",
        "  all_recommended_books = []\n",
        "\n",
        "  # Pass each title from top_books to looped_recommender\n",
        "  for book_info in top_books:\n",
        "      _, title, _ = book_info\n",
        "      recommended_books_for_title = looped_recommender(title,num)\n",
        "\n",
        "      if recommended_books_for_title is None:\n",
        "        continue\n",
        "\n",
        "      all_recommended_books.extend(recommended_books_for_title)\n",
        "\n",
        "  # Ensure there are no duplicates across all recommendations\n",
        "  all_recommended_books = list(set(all_recommended_books))\n",
        "\n",
        "  matching_rows = find_rows_by_titles(original_book, all_recommended_books)\n",
        "\n",
        "  # Sort the DataFrame in descending order of rating\n",
        "  matching_df_sorted = matching_rows.sort_values(by='rating', ascending=False)\n",
        "\n",
        "# 'matching_df_sorted' will contain the rows sorted by rating in descending order\n",
        "\n",
        "\n",
        "  return matching_df_sorted[:num]"
      ],
      "metadata": {
        "id": "bd7dilDx6qhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collaborative_based_for_hybrid_system(user_id, model, lbl_books, num_of_recommendation,device):\n",
        "\n",
        "  collaborative_based_recommendations, predicted_ratings = recommend_books_for_collaborative(user_id, model, lbl_books, num_of_recommendation,device)\n",
        "  if collaborative_based_recommendations is None:\n",
        "        return None\n",
        "  # print(f\"Top {num_of_recommendation} recommended books with ratings for user {user_id}:\")\n",
        "  book_data = []\n",
        "  for i, (book_id, rating) in enumerate(zip(collaborative_based_recommendations, predicted_ratings)):\n",
        "      # Find the row in the books_for_collaborative_based DataFrame with the matching book_id\n",
        "        book_row = books_for_collaborative_based[books_for_collaborative_based['book_id'] == book_id]\n",
        "\n",
        "        # Check if a matching row was found\n",
        "        if not book_row.empty:\n",
        "            # Append the entire row to the book_data list\n",
        "            book_data.append(book_row.iloc[0])  # Assuming there's only one matching row\n",
        "\n",
        "    # Create a DataFrame from the list of rows\n",
        "  recommended_books_df = pd.DataFrame(book_data)\n",
        "  return recommended_books_df"
      ],
      "metadata": {
        "id": "Gy9vzkkZW7Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 87\n",
        "num_of_recommendation = 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Content-Based Recommendations\n",
        "list_of_genres = ['Cultural','Environmental','Business','Animals']\n",
        "content_based_recommendations = content_based_for_hybrid_system(list_of_genres,num_of_recommendation)\n",
        "\n",
        "# content_based_recommendations\n",
        "\n",
        "# Collaborative-Based Recommendations\n",
        "collaborative_based_recommendations = collaborative_based_for_hybrid_system(user_id, model, lbl_books, num_of_recommendation,device)\n",
        "\n",
        "# Combine content-based and collaborative-based recommendations\n",
        "if collaborative_based_recommendations is not None:\n",
        "  combined_recommendations = pd.concat([content_based_recommendations, collaborative_based_recommendations])\n",
        "else:\n",
        "  combined_recommendations = content_based_recommendations\n",
        "\n",
        "# Print the combined recommendations DataFrame\n",
        "# Assuming combined_recommendations is a Pandas DataFrame with the specified columns\n",
        "\n",
        "# Concatenate df1 and df2 vertically\n",
        "combined_df = pd.concat([content_based_recommendations, collaborative_based_recommendations])\n",
        "\n",
        "# Print the combined DataFrame\n",
        "# content_based_recommendations\n",
        "# collaborative_based_recommendations\n",
        "combined_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "HTbEjhgqanze",
        "outputId": "5d9e4c50-6d86-41a6-ff51-dbb79aeb5f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ratings:  [(417, 5.5364485e-08), (697, 5.1151563e-08), (919, 4.624921e-08)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     book_id                                              title        isbn  \\\n",
              "6       9747  A Predictable Tragedy: Robert Mugabe and the C...  081224267X   \n",
              "4       8001  Soweto Inside Out: Stories About Africa's Famo...   143024590   \n",
              "5       9059                Freak Out! My Life with Frank Zappa   859654796   \n",
              "416      417          In the Line of Fire (Uniformly Hot!, #15)   373796021   \n",
              "696      697  Green Babies, Sage Moms: The Ultimate Guide to...  045122289X   \n",
              "918      919  Krav Maga: How to Defend Yourself Against Arme...  1583940081   \n",
              "\n",
              "                                     author  \\\n",
              "6                          Daniel Compagnon   \n",
              "4    Adam   Roberts,Joe Thloloe,Tim Butcher   \n",
              "5                           Pauline Butcher   \n",
              "416                      Jennifer LaBrecque   \n",
              "696                 Lynda Fassa,Harvey Karp   \n",
              "918                              Imi Sde-Or   \n",
              "\n",
              "                                                 genre  \\\n",
              "6                                     Africa, Cultural   \n",
              "4                         Africa, Cultural, Nonfiction   \n",
              "5              Autobiography, Biography, Memoir, Music   \n",
              "416  Category Romance, Contemporary, Contemporary R...   \n",
              "696          Environment, Green, Nonfiction, Parenting   \n",
              "918   Combat, Health, Martial Arts, Nonfiction, Sports   \n",
              "\n",
              "                                           description  \\\n",
              "6    When the southern African country of Rhodesia ...   \n",
              "4    This is a title about Soweto from inside and o...   \n",
              "5    In 1967, 21-year-old Pauline Butcher was worki...   \n",
              "416  Subject: Colton Sawyer, Army Officer.Current S...   \n",
              "696  From the trailblazing founder of Green Babies ...   \n",
              "918  Krav Maga is today's cutting edge self-defense...   \n",
              "\n",
              "                                                 image  pages  rating  \\\n",
              "6    https://i.gr-assets.com/images/S/compressed.ph...    333    4.22   \n",
              "4    https://i.gr-assets.com/images/S/compressed.ph...    237    4.00   \n",
              "5    https://i.gr-assets.com/images/S/compressed.ph...    320    3.94   \n",
              "416  https://i.gr-assets.com/images/S/compressed.ph...    224    3.81   \n",
              "696  https://i.gr-assets.com/images/S/compressed.ph...    234    3.31   \n",
              "918  https://i.gr-assets.com/images/S/compressed.ph...    256    3.93   \n",
              "\n",
              "     total_ratings language  \n",
              "6                9       en  \n",
              "4               21       en  \n",
              "5              199       en  \n",
              "416            139       en  \n",
              "696            143       en  \n",
              "918            135       en  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c226218e-dc94-4494-a792-b91235ee0adc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>title</th>\n",
              "      <th>isbn</th>\n",
              "      <th>author</th>\n",
              "      <th>genre</th>\n",
              "      <th>description</th>\n",
              "      <th>image</th>\n",
              "      <th>pages</th>\n",
              "      <th>rating</th>\n",
              "      <th>total_ratings</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>9747</td>\n",
              "      <td>A Predictable Tragedy: Robert Mugabe and the C...</td>\n",
              "      <td>081224267X</td>\n",
              "      <td>Daniel Compagnon</td>\n",
              "      <td>Africa, Cultural</td>\n",
              "      <td>When the southern African country of Rhodesia ...</td>\n",
              "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
              "      <td>333</td>\n",
              "      <td>4.22</td>\n",
              "      <td>9</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8001</td>\n",
              "      <td>Soweto Inside Out: Stories About Africa's Famo...</td>\n",
              "      <td>143024590</td>\n",
              "      <td>Adam   Roberts,Joe Thloloe,Tim Butcher</td>\n",
              "      <td>Africa, Cultural, Nonfiction</td>\n",
              "      <td>This is a title about Soweto from inside and o...</td>\n",
              "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
              "      <td>237</td>\n",
              "      <td>4.00</td>\n",
              "      <td>21</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>9059</td>\n",
              "      <td>Freak Out! My Life with Frank Zappa</td>\n",
              "      <td>859654796</td>\n",
              "      <td>Pauline Butcher</td>\n",
              "      <td>Autobiography, Biography, Memoir, Music</td>\n",
              "      <td>In 1967, 21-year-old Pauline Butcher was worki...</td>\n",
              "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
              "      <td>320</td>\n",
              "      <td>3.94</td>\n",
              "      <td>199</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>417</td>\n",
              "      <td>In the Line of Fire (Uniformly Hot!, #15)</td>\n",
              "      <td>373796021</td>\n",
              "      <td>Jennifer LaBrecque</td>\n",
              "      <td>Category Romance, Contemporary, Contemporary R...</td>\n",
              "      <td>Subject: Colton Sawyer, Army Officer.Current S...</td>\n",
              "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
              "      <td>224</td>\n",
              "      <td>3.81</td>\n",
              "      <td>139</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>697</td>\n",
              "      <td>Green Babies, Sage Moms: The Ultimate Guide to...</td>\n",
              "      <td>045122289X</td>\n",
              "      <td>Lynda Fassa,Harvey Karp</td>\n",
              "      <td>Environment, Green, Nonfiction, Parenting</td>\n",
              "      <td>From the trailblazing founder of Green Babies ...</td>\n",
              "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
              "      <td>234</td>\n",
              "      <td>3.31</td>\n",
              "      <td>143</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>918</th>\n",
              "      <td>919</td>\n",
              "      <td>Krav Maga: How to Defend Yourself Against Arme...</td>\n",
              "      <td>1583940081</td>\n",
              "      <td>Imi Sde-Or</td>\n",
              "      <td>Combat, Health, Martial Arts, Nonfiction, Sports</td>\n",
              "      <td>Krav Maga is today's cutting edge self-defense...</td>\n",
              "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
              "      <td>256</td>\n",
              "      <td>3.93</td>\n",
              "      <td>135</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c226218e-dc94-4494-a792-b91235ee0adc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c226218e-dc94-4494-a792-b91235ee0adc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c226218e-dc94-4494-a792-b91235ee0adc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1180916c-9826-4514-a0db-b53c74fcbb03\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1180916c-9826-4514-a0db-b53c74fcbb03')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1180916c-9826-4514-a0db-b53c74fcbb03 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}